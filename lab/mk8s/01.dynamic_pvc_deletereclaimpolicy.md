# Dynamic PVC with network-ssd disk

## Описание.
Создадим pvc на базе yc-network-ssd диска. С reclaimPolicy: delete. Примонтируем к поду и убедимся, что монтирование есть.
После этого удалим pod, pvc. И проверим остался ли диск в облаке.
Эксперимент проводим на версии кластера 1.29.

## Поехали!

### Создаём PVC.
```
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-dynamic
  namespace: default
  labels:
    cam: pvc-dynamic
  annotations:
    author: cameda
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: yc-network-ssd
  resources:
    requests:
      storage: 12Gi
```
PVC повис в состоянии Pending - это нормально. Потому что в StorageClass указано поле: VolumeBindingMode: WaitForFirstConsumer.
Оно означает, что пока нет пода, к которому этот PVC будет примонтирован, не будет создаваться и PV.
```
kubectl get pvc -owide
NAME          STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS     VOLUMEATTRIBUTESCLASS   AGE   VOLUMEMODE
pvc-dynamic   Pending                                      yc-network-ssd   <unset>                 18s   Filesystem
```
### Теперь создаём под, к которому примонтируем этот PVC.
```
apiVersion: v1
kind: Pod
metadata:
  name: cam-pod-busybox
  namespace: default
  labels:
    cam: busybox
  annotations:
    author: cameda
spec:
  containers:
  - name: busybox
    image: busybox
    imagePullPolicy: IfNotPresent
    resources:
      requests:
        cpu: "100m"
        memory: "120Mi"
      limits:
        memory: "200Mi"
    command: ["sh", "-c"]
    args: ["sleep 240h"]
    volumeMounts:
    - name: persistent-storage
      mountPath: /data
  restartPolicy: OnFailure
  hostname: busybox
  nodeSelector:
    kubernetes.io/os: linux
  volumes:
  - name: persistent-storage
    persistentVolumeClaim:
      claimName: pvc-dynamic
```

### Pod и PVC создались.
```
kubectl get po cam-pod-busybox -owide
NAME              READY   STATUS    RESTARTS   AGE   IP             NODE                        NOMINATED NODE   READINESS GATES
cam-pod-busybox   1/1     Running   0          30s   10.36.128.21   cl1kdqsq1ndr56qkigmr-ozux   <none>           <none>

kubectl get pvc -owide
NAME          STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS     VOLUMEATTRIBUTESCLASS   AGE     VOLUMEMODE
pvc-dynamic   Bound    pvc-0d96a55e-2bea-49d9-8fd4-601602ef6442   12Gi       RWO            yc-network-ssd   <unset>                 8m28s   Filesystem

kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                 STORAGECLASS     VOLUMEATTRIBUTESCLASS   REASON   AGE
pvc-0d96a55e-2bea-49d9-8fd4-601602ef6442   12Gi       RWO            Delete           Bound    default/pvc-dynamic   yc-network-ssd   <unset>                          2m41s

kubectl describe pv pvc-0d96a55e-2bea-49d9-8fd4-601602ef6442
Name:              pvc-0d96a55e-2bea-49d9-8fd4-601602ef6442
Labels:            <none>
Annotations:       pv.kubernetes.io/provisioned-by: disk-csi-driver.mks.ycloud.io
                   volume.kubernetes.io/provisioner-deletion-secret-name:
                   volume.kubernetes.io/provisioner-deletion-secret-namespace:
Finalizers:        [kubernetes.io/pv-protection external-attacher/disk-csi-driver-mks-ycloud-io]
StorageClass:      yc-network-ssd
Status:            Bound
Claim:             default/pvc-dynamic
Reclaim Policy:    Delete
Access Modes:      RWO
VolumeMode:        Filesystem
Capacity:          12Gi
Node Affinity:
  Required Terms:
    Term 0:        failure-domain.beta.kubernetes.io/zone in [ru-central1-a]
Message:
Source:
    Type:              CSI (a Container Storage Interface (CSI) volume source)
    Driver:            disk-csi-driver.mks.ycloud.io
    FSType:            ext4
    VolumeHandle:      fhm6ktm2ul6af16ldmoh
    ReadOnly:          false
    VolumeAttributes:      storage.kubernetes.io/csiProvisionerIdentity=1721416109124-8081-disk-csi-driver.mks.ycloud.io
                           type=network-ssd
Events:                <none>
```

### В результате в облаке создался диск с идентификатором fhm6ktm2ul6af16ldmoh. Reclaim Policy: Delete у PV.
```
yc compute disk get fhm6ktm2ul6af16ldmoh
id: fhm6ktm2ul6af16ldmoh
folder_id: xxxxxxxxxxxxxxxxxx
created_at: "2024-07-20T09:31:20Z"
name: k8s-csi-0f8a75f8c7c398054ec809c744b70e2768e51e3c
labels:
  cluster-name: catr6ekt7bec23oogide
  volume-name: pvc-0d96a55e-2bea-49d9-8fd4-601602ef6442
type_id: network-ssd
zone_id: ru-central1-a
size: "12884901888"
block_size: "4096"
status: READY
instance_ids:
  - fhm68qvv5lmcj10asn20
disk_placement_policy: {}
```

### Подключимся к поду.
```
kubectl exec -ti cam-pod-busybox -- sh
```
Каталог data есть.

## Теперь удалим pod и pvc.
```
kubectl delete po cam-pod-busybox
kubectl delete pvc pvc-dynamic
```

### Диск удалён.
```
yc compute disk get fhm6ktm2ul6af16ldmoh
ERROR: disk with id or name "fhm6ktm2ul6af16ldmoh" not found
```
